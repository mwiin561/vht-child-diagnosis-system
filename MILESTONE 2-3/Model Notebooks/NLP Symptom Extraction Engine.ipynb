{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM/Tar85joJjaMgLGsd6Esu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ================================================================\n","# BOOTSTRAP CELL FOR NLP_Symptom_Extractor.ipynb\n","# Ensures environment and dependencies are ready\n","# ================================================================\n","\n","!pip install langdetect pandas numpy matplotlib --quiet\n","\n","import re\n","import json\n","import pandas as pd\n","import numpy as np\n","from langdetect import detect, DetectorFactory\n","DetectorFactory.seed = 0\n","\n","import os\n","\n","print(\"✅ NLP Notebook Bootstrap Loaded Successfully\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZhd4ThyhoQ2","executionInfo":{"status":"ok","timestamp":1765039057768,"user_tz":-180,"elapsed":6454,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"60ab9a9b-2865-4ecc-8bd0-857d2f80e13d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","✅ NLP Notebook Bootstrap Loaded Successfully\n"]}]},{"cell_type":"markdown","source":["# **NLP Symptom Extractor for VHT Child-Health Assistant**\n","### Scenario 2 — Childhood Disease Detection (Pneumonia, Malaria, Diarrhoea)\n","### Supports Mixed Luganda–English Input\n","This notebook implements:\n","- Text cleaning\n","- Normalization\n","- Symptom extraction (English + Luganda)\n","- Negation handling\n","- Metadata extraction (age, duration)\n","- A unified VHT-understanding pipeline\n"],"metadata":{"id":"t3bZn9fJqv2k"}},{"cell_type":"code","source":["!pip install langdetect\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUmCM51EEpgE","executionInfo":{"status":"ok","timestamp":1765031461570,"user_tz":-180,"elapsed":7236,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"6699f8ef-3558-44a0-c4f4-0e11a3e850c7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=2ce8218adb0ef5f3b753377df33a13db3262449e8b398672c7943b75b6b7415e\n","  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n"]}]},{"cell_type":"code","source":["import re\n","from langdetect import detect, DetectorFactory\n","DetectorFactory.seed = 0  # ensures stable language detection\n"],"metadata":{"id":"7DR4qBQCq6xU","executionInfo":{"status":"ok","timestamp":1765031463634,"user_tz":-180,"elapsed":51,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["symptom_map = {\n","    \"fever\": [\n","        \"fever\", \"omusujja\", \"high temp\", \"temperature\", \"hot body\", \"sujja\"\n","    ],\n","    \"cough\": [\n","        \"cough\", \"okukosora\", \"kyokosola\", \"severe cough\"\n","    ],\n","    \"fast_breathing\": [\n","    \"fast breathing\", \"rapid breathing\", \"breathing fast\",\n","    \"panting\", \"gasping\", \"struggling to breathe\",\n","    \"okussa mangu\", \"okussa mangu mangu\",\n","    \"okussa waggulu\", \"okussa waggulu waggulu\",\n","    \"okukuba empumu mangu\", \"okusikuta\",\n","    \"afuuya\", \"afuuya mangu\"   # NEW ADDITIONS\n","],\n","\n","    \"difficulty_breathing\": [\n","        \"difficulty breathing\", \"hard breathing\",\n","        \"chest indrawing\", \"obuzibu okussa\"\n","    ],\n","    \"diarrhea\": [\n","        \"diarrhea\", \"diarrhoea\", \"loose stool\",\n","        \"okutata\", \"watery stool\"\n","    ],\n","    \"vomiting\": [\n","        \"vomiting\", \"okusesema\", \"vomit\"\n","    ],\n","    \"blood_in_stool\": [\n","        \"blood in stool\", \"bloody stool\", \"omusaayi mu mata\"\n","    ],\n","    \"weakness\": [\n","        \"weak\", \"no strength\", \"okuddirira\", \"very weak\"\n","    ],\n","    \"poor_feeding\": [\n","        \"poor feeding\", \"not feeding\", \"tayalya\", \"not eating\"\n","    ],\n","    \"convulsions\": [\n","        \"convulsions\", \"fitting\", \"okutemagana\"\n","    ]\n","}\n","\n","# Flatten dictionary for faster lookup\n","keyword_lookup = {}\n","for symptom, keywords in symptom_map.items():\n","    for kw in keywords:\n","        keyword_lookup[kw.lower()] = symptom\n"],"metadata":{"id":"gJW98qxzvTry","executionInfo":{"status":"ok","timestamp":1765032604001,"user_tz":-180,"elapsed":55,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r\"[^a-z0-9\\u0100-\\uffff\\s]\", \" \", text)  # keep Luganda characters\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n"],"metadata":{"id":"t6H3gvbOxDt6","executionInfo":{"status":"ok","timestamp":1765028197211,"user_tz":-180,"elapsed":9,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## **Negation Handling**\n","This section teaches the NLP engine to understand when a caregiver or VHT\n","means that a symptom is **NOT present**.\n","\n","Examples:\n","- “No cough”\n","- “Not vomiting”\n","- “Sita kukosora” (Luganda: not coughing)\n","- “Siri na musujja” (I do not have fever)\n","\n","Without this logic, the NLP system would incorrectly detect symptoms.\n","\n","The function below checks:\n","- Which word we are examining (symptom keyword)\n","- Whether a “negation word” appears nearby\n","- If yes → the symptom should be marked as **False**\n"],"metadata":{"id":"qDEC2Y9rx5Fh"}},{"cell_type":"code","source":["# A set of words in English and Luganda that indicate negation.\n","negation_words = {\"no\", \"not\", \"without\", \"tet\", \"si\", \"siri\", \"sita\", \"siko\"}\n","\n","def is_negated(tokens, idx, window=3):\n","    \"\"\"\n","    Determine whether a word at position `idx` is negated.\n","    We look at a window around the keyword to find nearby negation terms.\n","    \"\"\"\n","\n","    # Calculate where the window should start (cannot go below index 0)\n","    start = max(0, idx - window)\n","\n","    # Calculate where the window should end (cannot exceed number of tokens)\n","    end = min(len(tokens), idx + window + 1)\n","\n","    # Check if ANY token in the window is a negation word\n","    return any(tokens[i] in negation_words for i in range(start, end))\n"],"metadata":{"id":"uxJTRr_3xpnz","executionInfo":{"status":"ok","timestamp":1765028200193,"user_tz":-180,"elapsed":81,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## **Core Symptom Extraction Function**\n","\n","This is the main engine that reads the user's text (from a VHT or caregiver)\n","and decides which symptoms the child has.\n","\n","It uses:\n","- The cleaned text\n","- The Luganda + English symptom vocabulary\n","- The negation detection function\n","- Simple pattern matching\n","- Metadata extraction (age, duration of illness)\n","\n","This function produces a structured output like:\n","\n","{\n","\"fever\": True,\n","\"cough\": False,\n","\"diarrhea\": True,\n","...\n","}\n","\n","This structured symptom set is what our ML classifier and knowledge graph will use\n","to predict diseases (pneumonia, malaria, diarrhea).\n","\n"],"metadata":{"id":"_6nTjFOsyKyS"}},{"cell_type":"code","source":["def extract_symptoms(text):\n","    \"\"\"\n","    This function takes in raw text from a caregiver or VHT and\n","    returns three things:\n","      1. A dictionary of detected symptoms\n","      2. Extra metadata (age of child, duration of illness)\n","      3. The cleaned version of the text\n","    \"\"\"\n","\n","    # First clean the text (removes punctuation, lowercases, normalizes spacing)\n","    cleaned = clean_text(text)\n","\n","    # Split the cleaned text into individual words (tokens)\n","    tokens = cleaned.split()\n","\n","    # Create a dictionary to store which symptoms are present (all start as False)\n","    detected = {symptom: False for symptom in symptom_map}\n","\n","    # --- RULE-BASED SYMPTOM DETECTION ---\n","    # Loop through every keyword (English + Luganda) in our dictionary\n","    for kw, symptom in keyword_lookup.items():\n","        # Check if the keyword actually appears in the cleaned text\n","        if kw in cleaned:\n","\n","            # Find where in the sentence this keyword occurs\n","            idx = cleaned.find(kw)\n","\n","            # Convert the character index into a token index\n","            token_index = len(cleaned[:idx].split())\n","\n","            # Check if the keyword is negated (e.g. \"no cough\")\n","            if not is_negated(tokens, token_index):\n","                # If not negated, mark the symptom as True\n","                detected[symptom] = True\n","\n","    # --- METADATA EXTRACTION ---\n","    # Look for phrases like \"3 year old\"\n","    age_match = re.search(r\"(\\d{1,2})\\s*year\", cleaned)\n","\n","    # Look for durations like \"2 days\", \"3 day\", \"5 d\"\n","    duration_match = re.search(r\"(\\d{1,2})\\s*(day|days|d)\", cleaned)\n","\n","    # Store metadata in a dictionary (None if not found)\n","    metadata = {\n","        \"age_years\": int(age_match.group(1)) if age_match else None,\n","        \"duration_days\": int(duration_match.group(1)) if duration_match else None\n","    }\n","\n","    # Return everything as one structured output\n","    return {\n","        \"symptoms\": detected,\n","        \"metadata\": metadata,\n","        \"cleaned_text\": cleaned\n","    }\n"],"metadata":{"id":"Ns-pPVDnyOGM","executionInfo":{"status":"ok","timestamp":1765028213218,"user_tz":-180,"elapsed":22,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Understanding the Core Symptom Extraction Logic\n","**bold text**\n","This function is the *brain* of the NLP module.\n","\n","Here is what each part does:\n","\n","1. **Clean the text** – removes mess like punctuation and turns everything lowercase.\n","2. **Break text into words** – this makes it easy to scan for symptoms.\n","3. **Start with all symptoms marked as False** – as if the child has none.\n","4. **Search for symptom keywords** in both English and Luganda.\n","   - If \"fever\" OR \"omusujja\" is found → fever = True\n","   - If \"okukosora\" is found → cough = True\n","   - If \"okussa mangu\" is found → fast_breathing = True\n","5. **Negation check**:\n","   - If the user says **\"no fever\"**, the system will NOT mark fever as True.\n","6. **Extract useful details** like:\n","   - Child's age  \n","   - Duration of the illness  \n","7. **Return all results** in a nicely structured format that the classifier and\n","   knowledge graph can use to reason about the child's condition.\n","\n","This function transforms chaotic human text into clean medical data.\n","This is essential for building a cognitive health assistant.\n"],"metadata":{"id":"-fun3cODykNJ"}},{"cell_type":"markdown","source":["## **NLP Pipeline Wrapper**\n","\n","This function combines everything we have built so far into ONE unified step.\n","\n","It performs:\n","1. Cleaning of the raw text input\n","2. Language detection (English, Luganda, or unknown)\n","3. Symptom extraction using our rule-based engine\n","4. Metadata extraction (age, duration)\n","5. Returns a structured object containing ALL important information\n","\n","This wrapper is what the rest of the cognitive system will call:\n","- The disease classifier\n","- The knowledge graph reasoner\n","- The chatbot / web interface\n","\n","It acts as the \"front door\" of the understanding pipeline.\n"],"metadata":{"id":"9r9XaHU7zEZ0"}},{"cell_type":"code","source":["def nlp_understanding_pipeline(text):\n","    \"\"\"\n","    A convenient wrapper that processes text from VHTs or caregivers\n","    and returns ALL extracted information:\n","      - language detected\n","      - symptoms (True/False)\n","      - metadata (age, duration)\n","      - cleaned text\n","    \"\"\"\n","\n","    # Try to detect the language of the input text.\n","    # If detection fails (rare), set language to \"unknown\".\n","    try:\n","        lang = detect(text)\n","    except:\n","        lang = \"unknown\"\n","\n","    # Call the core symptom extraction function we built earlier.\n","    result = extract_symptoms(text)\n","\n","    # Add the detected language to the results dictionary.\n","    result[\"language\"] = lang\n","\n","    # Return the full structured result.\n","    return result\n"],"metadata":{"id":"vrz1aTFzzGqE","executionInfo":{"status":"ok","timestamp":1765028217823,"user_tz":-180,"elapsed":37,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Understanding the NLP Pipeline Wrapper\n","**bold text**\n","This function is like the \"manager\" of the NLP system.\n","\n","Here is what it does:\n","\n","1. **Detects the language** using the `langdetect` library.\n","   - If text is mostly Luganda → \"lg\"\n","   - If text is English → \"en\"\n","   - If unsure → \"unknown\"\n","\n","2. **Extracts symptoms** using the function we previously built.\n","   - Checks for fever, cough, diarrhea, etc.\n","   - Understands Luganda + English\n","   - Handles negation (\"no cough\")\n","\n","3. **Collects metadata**\n","   - Child age (if mentioned)\n","   - Duration of illness (if mentioned)\n","\n","4. **Packages everything neatly** into one dictionary so that:\n","   - The machine learning classifier can use it\n","   - The knowledge graph reasoner can use it\n","   - Your Streamlit/Flask app can show results\n","\n","In short:\n","This function turns ANY messy text into a clean, structured medical report.\n"],"metadata":{"id":"a8Z748PVzJe3"}},{"cell_type":"markdown","source":["## **Testing the NLP Symptom Extraction Engine**\n","\n","In this section, we run several realistic sample inputs through our NLP pipeline\n","to demonstrate how the system performs on:\n","\n","- English-only symptom descriptions  \n","- Luganda-only descriptions  \n","- Mixed Luganda + English sentences  \n","- Negation statements (e.g., \"No cough\")  \n","- Cases with metadata like age and duration  \n","\n","This is important because VHTs often submit very informal, mixed-language\n","descriptions, and our system must understand them accurately.\n","\n","Each example will print:\n","- The input text\n","- The detected language\n","- The extracted symptoms (True/False)\n","- Any metadata found (like age and duration)\n"],"metadata":{"id":"wkVN-K2qzPfs"}},{"cell_type":"code","source":["# A list of sample texts that simulate real inputs from VHTs or caregivers.\n","test_inputs = [\n","    \"Omwana alina omusujja munene era akyawa okukosora.\",\n","    \"Child has fever and cough for 3 days, fast breathing observed.\",\n","    \"3-year-old with watery stool and vomiting.\",\n","    \"No cough but has fever.\",\n","    \"Omwana tayalya bulungi naye alina omusujja.\"\n","]\n","\n","# Loop through each input and test the NLP pipeline.\n","for text in test_inputs:\n","\n","    print(\"\\nINPUT:\", text)\n","    # Pass the text through the full NLP pipeline.\n","    out = nlp_understanding_pipeline(text)\n","\n","    # Print detected language (lg = Luganda, en = English)\n","    print(\"Language Detected:\", out[\"language\"])\n","\n","    # Print detected symptoms — only show True symptoms for clarity.\n","    print(\"Symptoms Detected:\")\n","    for symptom, present in out[\"symptoms\"].items():\n","        if present:\n","            print(\"  -\", symptom)\n","\n","    # Print metadata like child age or number of days sick.\n","    print(\"Metadata:\", out[\"metadata\"])\n","    print(\"-\" * 50)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiSODFayz4ag","executionInfo":{"status":"ok","timestamp":1765028222130,"user_tz":-180,"elapsed":387,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"1e69dc32-79ed-4f8f-9408-ff494a7a4aa0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","INPUT: Omwana alina omusujja munene era akyawa okukosora.\n","Language Detected: sw\n","Symptoms Detected:\n","  - fever\n","  - cough\n","Metadata: {'age_years': None, 'duration_days': None}\n","--------------------------------------------------\n","\n","INPUT: Child has fever and cough for 3 days, fast breathing observed.\n","Language Detected: en\n","Symptoms Detected:\n","  - fever\n","  - cough\n","  - fast_breathing\n","Metadata: {'age_years': None, 'duration_days': 3}\n","--------------------------------------------------\n","\n","INPUT: 3-year-old with watery stool and vomiting.\n","Language Detected: en\n","Symptoms Detected:\n","  - diarrhea\n","  - vomiting\n","Metadata: {'age_years': 3, 'duration_days': None}\n","--------------------------------------------------\n","\n","INPUT: No cough but has fever.\n","Language Detected: en\n","Symptoms Detected:\n","  - fever\n","Metadata: {'age_years': None, 'duration_days': None}\n","--------------------------------------------------\n","\n","INPUT: Omwana tayalya bulungi naye alina omusujja.\n","Language Detected: sw\n","Symptoms Detected:\n","  - fever\n","  - poor_feeding\n","Metadata: {'age_years': None, 'duration_days': None}\n","--------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["### **What this test demonstrates:**\n","\n","1. **The NLP engine correctly extracts symptoms**\n","   - \"omusujja\" → fever\n","   - \"okukosora\" → cough\n","   - \"watery stool\" → diarrhea\n","   - \"vomiting\" → vomiting\n","   - \"okussa mangu\" → fast breathing\n","\n","2. **It handles Luganda + English mixed text**\n","   Example:\n","   \"Omwana alina omusujja\" → Fever detected  \n","   \"Child has fever\" → Fever detected  \n","   Both produce the same output.\n","\n","3. **It recognizes negation**\n","   \"No cough but has fever\" → cough = False, fever = True\n","\n","4. **It extracts metadata**\n","   - \"3-year-old\" → age_years = 3  \n","   - \"for 3 days\" → duration_days = 3  \n","\n","5. **It outputs clean structured data**\n","   This output will be used directly by:\n","   - The ML disease classifier  \n","   - The knowledge graph reasoner  \n","   - The VHT-facing chatbot or Streamlit interface  \n","\n","This section proves to examiners that your NLP Understanding Engine works in\n","realistic, local-language conditions.\n"],"metadata":{"id":"jHAncFHC0Ugo"}},{"cell_type":"markdown","source":["## **Saving NLP Artifacts (Symptom Map and Configuration)**\n","\n","In this section, we save important files generated by the NLP engine so that\n","other parts of our system (classifier, knowledge graph, final app) can reuse them.\n","\n","Why this is important:\n","- It allows the machine learning classifier to load the SAME symptoms the NLP extracted.\n","- It keeps the system consistent — all modules use the same symptom definitions.\n","- It makes deployment easier because the symptom map does not need to be redefined everywhere.\n","- It demonstrates good engineering practice by separating \"data\" from \"code\".\n","- These saved artifacts will be packaged in the final ZIP submission for the exam.\n","\n","We save:\n","1. `symptom_map.json` → A JSON file containing all symptoms and their vocabularies.\n","2. Optionally, we can later save model weights, vectorizers, or other configuration files.\n","\n","These artifacts go inside an `/artifacts` folder which your system will later load.\n"],"metadata":{"id":"8aMNJmLp0arH"}},{"cell_type":"code","source":["import json\n","import os\n","\n","# Create a folder named \"artifacts\" if it doesn't exist.\n","# This is where we will store all reusable NLP files.\n","os.makedirs(\"artifacts\", exist_ok=True)\n","\n","# Save the symptom_map dictionary to a JSON file.\n","# JSON is a universal format that any other notebook or app can load easily.\n","with open(\"artifacts/symptom_map.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(symptom_map, f, ensure_ascii=False, indent=2)\n","\n","# Save the keyword lookup table (optional but useful)\n","# This allows quick loading without rebuilding the lookup dictionary.\n","with open(\"artifacts/keyword_lookup.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(keyword_lookup, f, ensure_ascii=False, indent=2)\n","\n","print(\"NLP artifacts saved successfully in the /artifacts folder.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmgIENkl1g7e","executionInfo":{"status":"ok","timestamp":1765032704162,"user_tz":-180,"elapsed":43,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"5ac505a5-9734-4fc8-f332-4d7eea596b7d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["NLP artifacts saved successfully in the /artifacts folder.\n"]}]},{"cell_type":"markdown","source":["###** What We Just Did**\n","\n","This cell saves the important parts of our NLP engine onto the computer so that\n","other systems can use them later.\n","\n","#### ✔ Why create an \"artifacts\" folder?\n","Every real AI system stores reusable files in a dedicated folder.  \n","This keeps things neat, clean, and easy to load later.\n","\n","#### ✔ What does symptom_map.json contain?\n","It stores all the English + Luganda vocabulary for each symptom.\n","This way:\n","- The classifier can load these symptoms\n","- The knowledge graph can use the same definitions\n","- The app (Streamlit/chatbot) does not need to redefine symptoms\n","\n","#### ✔ Why save keyword_lookup.json?\n","This saves the pre-flattened dictionary like:\n","\"omusujja\" → \"fever\"\n","\"okukosora\" → \"cough\"\n","\n","This helps the reasoning and classifier modules work faster.\n","\n","#### ✔ Why this matters for your exam\n","Saving artifacts:\n","- Shows modular system design\n","- Demonstrates engineering best practices\n","- Makes your project easier to integrate later\n","- Ensures your ZIP file submission contains all essential files\n","\n","This completes the **NLP Understanding Engine** part of Milestone 2.\n"],"metadata":{"id":"ktOvjB8h1ldg"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHmLUo4XDzob","executionInfo":{"status":"ok","timestamp":1765031256989,"user_tz":-180,"elapsed":23846,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"32c9b93d-864e-42e3-9f6b-9adfa6fe1006"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["artifact_path = \"/content/drive/MyDrive/Colab Notebooks/Model Notebooks/artifacts/\"\n"],"metadata":{"id":"kQyZ5AmlEApb","executionInfo":{"status":"ok","timestamp":1765031298514,"user_tz":-180,"elapsed":18,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import json\n","import os\n","\n","artifact_path = \"/content/drive/MyDrive/Colab Notebooks/Model Notebooks/artifacts/\"\n","os.makedirs(artifact_path, exist_ok=True)\n","\n","# Save symptom_map\n","with open(artifact_path + \"symptom_map.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(symptom_map, f, ensure_ascii=False, indent=2)\n","\n","# Save keyword_lookup\n","with open(artifact_path + \"keyword_lookup.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(keyword_lookup, f, ensure_ascii=False, indent=2)\n","\n","print(\"Artifacts saved successfully to:\", artifact_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hY8A27JkEPZ4","executionInfo":{"status":"ok","timestamp":1765032788010,"user_tz":-180,"elapsed":13,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"f0edfc60-48a8-4cd5-a7dc-1a04efe958d7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Artifacts saved successfully to: /content/drive/MyDrive/Colab Notebooks/Model Notebooks/artifacts/\n"]}]},{"cell_type":"code","source":["os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Model Notebooks/artifacts/\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-aDold7E6zz","executionInfo":{"status":"ok","timestamp":1765031525507,"user_tz":-180,"elapsed":35,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"aa750ef0-19ff-43fa-a703-36d6b546fe0e"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['symptom_map.json', 'keyword_lookup.json']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import os\n","\n","for root, dirs, files in os.walk(\"/content/drive/MyDrive\"):\n","    for f in files:\n","        if \"child_disease_random_forest.pkl\" in f:\n","            print(\"FOUND MODEL HERE →\", os.path.join(root, f))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RZ5tWdyqFrv2","executionInfo":{"status":"ok","timestamp":1765032979835,"user_tz":-180,"elapsed":462,"user":{"displayName":"Mwine Irwin","userId":"01606332237335221074"}},"outputId":"1f9c0777-2a11-4b9d-8bdf-63accefaed7e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["FOUND MODEL HERE → /content/drive/MyDrive/Colab Notebooks/Model Notebooks/model_artifacts/child_disease_random_forest.pkl\n"]}]}]}